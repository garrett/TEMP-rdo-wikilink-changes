<!DOCTYPE html>
<!--[if lt IE 7]> <html class="no-js lt-ie10 lt-ie9 lt-ie8 lt-ie7" lang="en-us"> <![endif]-->
<!--[if IE 7]> <html class="no-js lt-ie10 lt-ie9 lt-ie8" lang="en-us"> <![endif]-->
<!--[if IE 8]> <html class="no-js lt-ie10 lt-ie9" lang="en-us"> <![endif]-->
<!--[if IE 9]> <html class="no-js lt-ie10 lt-ie9" lang="en-us"> <![endif]-->
<!--[if lt IE 10]> <html class="no-js lt-ie10" lang="en-us"> <![endif]-->
<!--[if !IE]> > <![endif]-->
<html class='no-js' lang='en'>
<!-- <![endif] -->
<head>
<title>
TripleO-CLI &mdash;
RDO
</title>
<meta charset='utf-8'>
<meta content='' name='description'>
<meta content='' name='author'>
<meta content='initial-scale=1.0,user-scalable=no,maximum-scale=1,width=device-width' name='viewport'>

<link href='/images/favicon.ico' rel='shortcut icon'>
<link href='/images/apple-touch-icon-precomposed.png' rel='apple-touch-icon-precomposed'>
<link href='/images/apple-touch-icon-57x57-precomposed.png' rel='apple-touch-icon-precomposed' sizes='57x57'>
<link href='/images/apple-touch-icon-72x72-precomposed.png' rel='apple-touch-icon-precomposed' sizes='72x72'>
<link href='/images/apple-touch-icon-114x114-precomposed.png' rel='apple-touch-icon-precomposed' sizes='114x114'>
<link href="/stylesheets/application.css" rel="stylesheet" type="text/css" />
<link href="/stylesheets/print.css" rel="stylesheet" type="text/css" media="print" />
</head>
<body class=' source-md'>
<header class='masthead hidden-print' id='branding' role='banner'>
<a href='https://github.com/redhat-openstack/website/edit/master/source/install/tripleo-cli.html.md'>
<img alt='Edit on GitHub' data-canonical-src='/images/edit.png' src='/images/edit.png' style='position: absolute; top: 0; right: 0; border: 0;'>
</a>
<section class='hgroup'>
<h1>
<a href="/"><img id="logo" class="logo " alt="RDO" src="/images/rdo-logo-white.png" />
</a></h1>
</section>
<div id='access'>
<nav role='navigation'>
<ul class='nav nav-pills'>
<li class='nav-link-home' role='menuitem'>
<a href='/'>Home</a>
</li>

<li class='nav-link-blog' role='menuitem'>
<a href='/blog/'>Blog</a>
</li>

<li class='nav-link-events' role='menuitem'>
<a href='/events/'>Events</a>
</li>

<li class='nav-link-community' role='menuitem'>
<a href='/community/'>Community</a>
</li>

<li class='nav-link-docs' role='menuitem'>
<a href='/documentation/'>Docs</a>
</li>

<li class='nav-link-search' role='menuitem'>
<a href='/search/'>Search</a>
</li>

</ul>
</nav>

</div>
</header>

<section class='page-wrap' id='page-wrap'>
<section class='page' id='page'>
<section class='container content' id='content'>

<!--[if lt IE 7]>
<p class="chromeframe">You are using an outdated browser.
<a href="http://browsehappy.com/">Upgrade your browser today</a> or
<a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to better experience this site.</p>
<![endif]-->
<h1 id="triple-o-cli">Triple O-CLI</h1>

<h2 id="management-system-installation">Management System Installation</h2>

<p>Instack is used to create the undercloud. This can be either done on a fully virtualised environment or with bare metal. Follow the steps described in <a href="/install/deploying-an-rdo-undercloud-with-instack/">deploying an RDO Undercloud</a> to create the undercloud for this installation. The log for the instack install can be found in <code>~/.instack/install-undercloud.log</code></p>

<h2 id="environment-setup">Environment Setup</h2>

<p>To setup your shell environment with the correct configuration and authentication details for your deployment you will need to run the following commands.</p>

<pre class="highlight plaintext"><code>  source ~/deploy-overcloudrc&#x000A;  source ~/tripleo-undercloud-passwords&#x000A;  source ~/stackrc&#x000A;</code></pre>

<p>These will need to be entered each time you start a new shell session for the following commands in this page to work.</p>

<h2 id="infrastructure-setup">Infrastructure Setup</h2>

<p>You will need to register your bare-metal hardware as nodes in Ironic. This can be done in one of two ways, the first uses the command line utility register-nodes to add them based on a JSON file.</p>

<p>Option 1: Use register-nodes from os-cloud-config to load the nodes JSON. The JSON file should match the following structure.</p>

<pre class="highlight plaintext"><code>   [&#x000A;     {&#x000A;       "arch": "x86_64",&#x000A;       "pm_user": "stack",&#x000A;       "pm_addr": "192.168.122.1",&#x000A;       "pm_password": "-----BEGIN RSA PRIVATE KEY-----$SNIP-----END RSA PRIVATE KEY-----",&#x000A;       "pm_type": "pxe_ssh",&#x000A;       "mac": [&#x000A;         "00:0b:d0:69:7e:59"&#x000A;       ],&#x000A;       "cpu": "1",&#x000A;       "memory": "4096",&#x000A;       "disk": "40"&#x000A;     },&#x000A;     {&#x000A;       "arch": "x86_64",&#x000A;       "pm_user": "stack",&#x000A;       "pm_addr": "192.168.122.2",&#x000A;       "pm_password": "-----BEGIN RSA PRIVATE KEY-----$SNIP-----END RSA PRIVATE KEY-----",&#x000A;       "pm_type": "pxe_ssh",&#x000A;       "mac": [&#x000A;         "00:0b:d0:69:7e:58"&#x000A;       ],&#x000A;       "cpu": "1",&#x000A;       "memory": "4096",&#x000A;       "disk": "40"&#x000A;     }&#x000A;   ]&#x000A;</code></pre>

<p>This can then be loaded like this:</p>

<pre class="highlight plaintext"><code>  register-nodes --service-host undercloud --nodes $JSON_FILE&#x000A;</code></pre>

<p>Option 2: Use the ironic client and <code>ironic node-create</code> and <code>ironic port-create</code> to add them one at a time.</p>

<pre class="highlight plaintext"><code>  $ ironic node-create -d pxe_ssh \&#x000A;      -p cpus=1 -p memory_mb=4096 -p local_gb=40 -p cpu_arch=x86_64 \&#x000A;      -i ssh_username=stack -i ssh_virt_type=virsh -i ssh_address="192.168.122.1" -i ssh_key_contents="key"&#x000A;  +--------------+-------------------------------------------------------------------------+&#x000A;  | Property     | Value                                                                   |&#x000A;  +--------------+-------------------------------------------------------------------------+&#x000A;  | uuid         | 8d9e4de3-8a57-417e-8c96-789555be372c                                    |&#x000A;  | driver_info  | {u'ssh_username': u'stack', u'ssh_virt_type': u'virsh', u'ssh_address': |&#x000A;  |              | u'192.168.122.1', u'ssh_key_contents': u'key'}                          |&#x000A;  | extra        | {}                                                                      |&#x000A;  | driver       | pxe_ssh                                                                 |&#x000A;  | chassis_uuid | None                                                                    |&#x000A;  | properties   | {u'memory_mb': u'4096', u'cpu_arch': u'x86_64', u'local_gb': u'40',     |&#x000A;  |              | u'cpus': u'1'}                                                          |&#x000A;  +--------------+-------------------------------------------------------------------------+&#x000A;  $ ironic port-create -a "00:7e:11:29:45:4e" -n 8d9e4de3-8a57-417e-8c96-789555be372c&#x000A;  +-----------+--------------------------------------+&#x000A;  | Property  | Value                                |&#x000A;  +-----------+--------------------------------------+&#x000A;  | node_uuid | 8d9e4de3-8a57-417e-8c96-789555be372c |&#x000A;  | extra     | {}                                   |&#x000A;  | uuid      | 1b93f57b-2add-45ca-bac4-c8e104ef4d63 |&#x000A;  | address   | 00:7e:11:29:45:4e                    |&#x000A;  +-----------+--------------------------------------+&#x000A;  $ ironic node-set-power-state 8d9e4de3-8a57-417e-8c96-789555be372c off&#x000A;</code></pre>

<h2 id="openstack-setup">OpenStack Setup</h2>

<p>Flavors are used to assign roles in the deployment plan to specific nodes in your infrastructure. The connection between these is made by creating the flavors in Nova and the updating the deployment plan in Tuskar to reflect which flavors the roles should use.</p>

<p>The following example creates a different flavor for the four standard roles, however, sharing flavors between roles is possible.</p>

<pre class="highlight plaintext"><code>  nova flavor-create control auto 4096 40 2&#x000A;  nova flavor-create compute auto 1024 40 1&#x000A;  nova flavor-create cinder-storage auto 1024 40 1&#x000A;  nova flavor-create swift-storage auto 1024 40 1&#x000A;  deploy_kernel_id=$(glance image-show bm-deploy-kernel | awk ' / id / {print $4}')&#x000A;  deploy_ramdisk_id=$(glance image-show bm-deploy-ramdisk | awk ' / id / {print $4}')&#x000A;  nova flavor-key control set "cpu_arch"="x86_64" "baremetal:deploy_kernel_id"="$deploy_kernel_id" "baremetal:deploy_ramdisk_id"="$deploy_ramdisk_id"&#x000A;  nova flavor-key compute set "cpu_arch"="x86_64" "baremetal:deploy_kernel_id"="$deploy_kernel_id" "baremetal:deploy_ramdisk_id"="$deploy_ramdisk_id"&#x000A;  nova flavor-key cinder-storage set "cpu_arch"="x86_64" "baremetal:deploy_kernel_id"="$deploy_kernel_id" "baremetal:deploy_ramdisk_id"="$deploy_ramdisk_id"&#x000A;  nova flavor-key swift-storage set "cpu_arch"="x86_64" "baremetal:deploy_kernel_id"="$deploy_kernel_id" "baremetal:deploy_ramdisk_id"="$deploy_ramdisk_id"&#x000A;</code></pre>

<p>In the Deployment section which follows below, we will look at how to specify the flavors (with the command <code>tuskar plan-patch</code>) we want to use when we deploy.</p>

<p>Nova logs can be found under <code>/var/log/nova/</code>.</p>

<h2 id="deployment">Deployment</h2>

<p>To deploy the Overcloud a deployment plan needs to be created with the Tuskar planning service. This allows you to select various Roles that will be used in the deployment, scale them and it will then output Heat Orchestration Templates that can then be executed by Heat.</p>

<p>When Tuskar is installed it will create a default Plan called <code>overcloud</code> which should be used. At the moment only one deployment is supported within Tuskar. You can see this Deployment Plan with the command <code>tuskar plan-list</code>.</p>

<pre class="highlight plaintext"><code>  $ tuskar plan-list&#x000A;  +--------------------------------------+-----------+-------------+----------------------------------------------------+&#x000A;  | uuid                                 | name      | description | roles                                              |&#x000A;  +--------------------------------------+-----------+-------------+----------------------------------------------------+&#x000A;  | f57884c9-ed35-421e-b331-b2dc38b656af | overcloud | None        | controller, swift-storage, compute, cinder-storage |&#x000A;  +--------------------------------------+-----------+-------------+----------------------------------------------------+&#x000A;</code></pre>

<p>The plan by default has the roles controller swift-storage, compute and cinder-storage. These are the four roles that Tuskar comes with as standard. The roles can all be seen with the command <code>tuskar roles-list</code></p>

<pre class="highlight plaintext"><code>  $ tuskar role-list&#x000A;  +--------------------------------------+----------------+---------+------------------------------------------------------------------------------+&#x000A;  | uuid                                 | name           | version | description                                                                  |&#x000A;  +--------------------------------------+----------------+---------+------------------------------------------------------------------------------+&#x000A;  | 023031ea-2dd9-43b4-9dd2-e9ebfb71710c | cinder-storage | 1       | Common Block Storage Configuration                                           |&#x000A;  | 71f5b6c8-d423-482c-bc4a-e7103e67d7dc | swift-storage  | 1       | Common Swift Storage Configuration                                           |&#x000A;  | 950b6757-7804-41aa-93a7-f50b099b0159 | controller     | 1       | OpenStack control plane node. Can be wrapped in a ResourceGroup for scaling. |&#x000A;  |                                      |                |         |                                                                              |&#x000A;  | b2a5f50e-a088-45d1-b4ac-2751a607628a | compute        | 1       | OpenStack hypervisor node. Can be wrapped in a ResourceGroup for scaling.    |&#x000A;  |                                      |                |         |                                                                              |&#x000A;  +--------------------------------------+----------------+---------+------------------------------------------------------------------------------+&#x000A;</code></pre>

<p>To set the require attributes in the Deployment Plan use the Tuskar command plan-patch.</p>

<pre class="highlight plaintext"><code>  tuskar plan-patch -A $ATTRIBUTE1=$VALUE1 -A $ATTRIBUTE2=$VALUE2 ... $PLAN_ID&#x000A;</code></pre>

<p>A full list of the attributes and their current values can be seen in the output of <code>tuskar plan-show overcloud</code></p>

<p><strong>TODO: Get the user a full list of required attributes.</strong></p>

<p>At this stage we can use the attributes to control the flavor used by each role.</p>

<pre class="highlight plaintext"><code>  tuskar plan-patch -A compute-1::Flavor=compute $PLAN_ID&#x000A;  tuskar plan-patch -A swift-storage-1::Flavor=swift-storage $PLAN_ID&#x000A;  tuskar plan-patch -A controller-1::Flavor=controller $PLAN_ID&#x000A;  tuskar plan-patch -A cinder-storage-1::Flavor=cinder-storage $PLAN_ID&#x000A;</code></pre>

<p>Once the attributes have been set in the Deployment Plan it can be reviewed with plan-show as described above. After this has been checked the Heat templates can be retried from Tuskar and a stack create can be executed.</p>

<pre class="highlight plaintext"><code>  tuskar plan-templates -O tuskar_templates $PLAN_ID&#x000A;  heat stack-create -f tuskar_templates/plan.yaml \&#x000A;     -e tuskar_templates/environment.yaml \&#x000A;     overcloud&#x000A;</code></pre>

<p>If there are any problems with the Heat stack update, the Heat engine log under <code>/var/log/heat/engine.log</code> is a good place to start debugging.</p>

<h2 id="monitoring">Monitoring</h2>

<p>The ironic client can be used to view your infrastructure. To get an overview, use the following command which will list all registered nodes and the state of that node.</p>

<pre class="highlight plaintext"><code>  $ ironic node-list&#x000A;  +--------------------------------------+---------------+-------------+--------------------+-------------+&#x000A;  | UUID                                 | Instance UUID | Power State | Provisioning State | Maintenance |&#x000A;  +--------------------------------------+---------------+-------------+--------------------+-------------+&#x000A;  | b75f16bf-b76d-4a01-a2cf-a5a395bec765 | None          | power off   | None               | False       |&#x000A;  | 357e84e8-bf32-4a6a-8540-79a126070b8f | None          | power off   | None               | False       |&#x000A;  | 263ff2f1-2f75-4a9a-95aa-b475b9160ec4 | None          | power off   | None               | False       |&#x000A;  | 8412a224-634f-40a1-8aff-4b24148cb735 | None          | power off   | None               | False       |&#x000A;  +--------------------------------------+---------------+-------------+--------------------+-------------+&#x000A;</code></pre>

<p>To view the detail for each individual node, use the following command with the ID in the output from above.</p>

<pre class="highlight plaintext"><code>  $ ironic node-show 263ff2f1-2f75-4a9a-95aa-b475b9160ec4&#x000A;  +------------------------+--------------------------------------------------------------------------+&#x000A;  | Property               | Value                                                                    |&#x000A;  +------------------------+--------------------------------------------------------------------------+&#x000A;  | instance_uuid          | None                                                                     |&#x000A;  | target_power_state     | None                                                                     |&#x000A;  | properties             | {u'memory_mb': u'4096', u'cpu_arch': u'x86_64', u'local_gb': u'40',      |&#x000A;  |                        | u'cpus': u'1'}                                                           |&#x000A;  | maintenance            | False                                                                    |&#x000A;  | driver_info            | {u'ssh_username': u'stack', u'ssh_virt_type': u'virsh', u'ssh_address':  |&#x000A;  |                        | u'192.168.122.1', u'ssh_key_contents': u'-----BEGIN RSA PRIVATE KEY----- |&#x000A;  |                        | `&lt;SNIP&gt;`                                                                   |&#x000A;  |                        | -----END RSA                                                             |&#x000A;  |                        | PRIVATE KEY-----'}                                                       |&#x000A;  | extra                  | {}                                                                       |&#x000A;  | last_error             | None                                                                     |&#x000A;  | created_at             | 2015-02-05T13:50:36+00:00                                                |&#x000A;  | target_provision_state | None                                                                     |&#x000A;  | driver                 | pxe_ssh                                                                  |&#x000A;  | updated_at             | 2015-02-09T15:04:08+00:00                                                |&#x000A;  | instance_info          | {}                                                                       |&#x000A;  | chassis_uuid           | None                                                                     |&#x000A;  | provision_state        | None                                                                     |&#x000A;  | reservation            | None                                                                     |&#x000A;  | power_state            | power off                                                                |&#x000A;  | console_enabled        | False                                                                    |&#x000A;  | uuid                   | 263ff2f1-2f75-4a9a-95aa-b475b9160ec4                                     |&#x000A;  +------------------------+--------------------------------------------------------------------------+&#x000A;</code></pre>

<h2 id="post-deployment">Post-Deployment</h2>

<p>To scale a deployment, first you will need to update the deployment plan and then execute this plan with Heat. The following example shows how to scale the number of compute nodes to four.</p>

<p>First we need to retrieve the Plan ID. This can be seen in the output of <code>tuskar plan-list</code> or it can be programmatically retrieved with the following command:</p>

<pre class="highlight plaintext"><code>  PLAN_ID=$( tuskar plan-show overcloud | awk '$2=="uuid" {print $4}' )&#x000A;</code></pre>

<p>To see the current scale values for your roles, use the <code>tuskar plan-show</code> command. Since the output is large, we can focus on the relevant sections with this command. It will show you each of the roles and their autoscale value.</p>

<pre class="highlight plaintext"><code>  $ tuskar plan-show overcloud | grep "::count" -A 1&#x000A;  |             | name=swift-storage-1::count        |&#x000A;  |             | value=1                            |&#x000A;  --&#x000A;  |             | name=controller-1::count           |&#x000A;  |             | value=1                            |&#x000A;  --&#x000A;  |             | name=compute-1::count              |&#x000A;  |             | value=1                            |&#x000A;  --&#x000A;  |             | name=cinder-storage-1::count       |&#x000A;  |             | value=1                            &#x000A;</code></pre>

<p>The plan-patch command allows us to set the count for the role we want to scale.</p>

<pre class="highlight plaintext"><code>  tuskar plan-patch -A compute-1::count=4 $PLAN_ID&#x000A;</code></pre>

<p><strong>Note: At the moment only scaling up is supported.</strong></p>

<p>The format of the attribute name is the <code>$ROLE_NAME-$ROLE_VERSION::count</code>. Therefore to scale the swift-storage role it would be named <code>swift-storage-1::count</code>.</p>

<p>After updating the attribute, we need to output the Heat Orchestration Templates to then send these to Heat. This is done with the <code>tuskar plan-templates</code> command by passing an output directory and the Plan ID.</p>

<pre class="highlight plaintext"><code>  tuskar plan-templates -O tuskar_templates $PLAN_ID&#x000A;</code></pre>

<p>Finally we can perform a stack update with Heat.</p>

<pre class="highlight plaintext"><code>  heat stack-update -f "tuskar_templates/plan.yaml" \&#x000A;     -e "tuskar_templates/environment.yaml" \&#x000A;     overcloud&#x000A;</code></pre>

<p>If there are any problems with the Heat stack update, the Heat engine log under <code>/var/log/heat/engine.log</code> is a good place to start debugging.</p>

</section>
</section>
</section>
<footer class='text-center' id='footer'>
<hr class='visible-print'>
<div class='footer-rdo'>
<dl>
  <dt>Docs</dt>
  <dd><a href="/install/quickstart">Download</a></dd>
  <dd><a href="/rdo/faq">Common questions</a></dd>
  <dd><a href="/troubleshooting/">Troubleshooting</a></dd>
  <dd><a href="/rdo/">About RDO</a></dd>
</dl>

<dl>
  <dt>Use RDO</dt>
  <dd><a href="/install/quickstart">Quickstart</a></dd>
  <dd><a href="/rdo/release-cadence">Releases</a></dd>
  <dd><a href="http://trunk.rdoproject.org/">Trunk builds</a></dd>
</dl>

<dl>
  <dt>Community</dt>
  <dd><a href="/community/">Participate</a></dd>
  <dd><a href="http://ask.rdoproject.org/">Ask (Q&amp;A)</a></dd>
  <dd><a href="https://bugzilla.redhat.com/buglist.cgi?product=RDO&amp;query_format=advanced&amp;bug_status=NEW&amp;bug_status=ASSIGNED">Browse open issues</a></dd>
  <dd><a href="https://bugzilla.redhat.com/enter_bug.cgi?product=RDO">Report a problem</a></dd>
</dl>

<dl>
  <dt>Support</dt>
  <dd><a href="https://access.redhat.com/products/red-hat-openstack-platform/">Red Hat OpenStack Platform</a></dd>
  <dd><a href="https://www.redhat.com/mailman/listinfo/rdo-list">Contact us</a></dd>
</dl>

</div>

<ul class='footer-nav-list'>
<li><strong>RDO</strong> is a <strong>Red Hat</strong>-sponsored community project</li>
</ul>

<div class='copyright'>
&copy; 2016 RDO
<span class='legal'><a href="/legal/">Legal & Privacy</a></span>
</div>
<div class='edit-this-page'>
<a target="_blank" href="https://github.com/redhat-openstack/website/edit/master/source/install/tripleo-cli.html.md"><i class="icon fa fa-pencil"></i>Edit this page on GitHub</a>
</div>
<div class='last-modified'>
Page last modified
Mon 12 Oct 2015 12:22 UTC
</div>
</footer>


<script src="/javascripts/application.js" type="text/javascript"></script>

<!-- begin eloqua tracking -->
<script language='JavaScript' src='//www.redhat.com/j/elqNow/elqCfg.js' type='text/javascript'></script>
<script language='JavaScript' src='//www.redhat.com/j/elqNow/elqImg.js' type='text/javascript'></script>
<!-- end eloqua tracking -->
<!-- begin Omniture tracking -->
<!--
SiteCatalyst code version: H.25.4
Copyright 1996-2013 Adobe, Inc. All Rights Reserved
More info available at http://www.omniture.com
-->
<div id='oTags'>
<script src='//www.redhat.com/assets/js/noncms_s_code.js' type='text/javascript'></script>
<script>
   /* You may give each page an identifying name, server, and channel on the next lines. */
   var coreUrl = encodeURI(document.URL.split("?")[0]);
   var urlSplit = coreUrl.toLowerCase().split(/\//);
   var urlLast = urlSplit[urlSplit.length-1];
   var pageNameString = "";
   var minorSectionIndex = 3;
   if (urlSplit[3] == "promo") {
     minorSectionIndex = 4;
   }
   if (urlLast == "") {
     urlSplit.splice(-1,1);
   }
   if (urlLast.search(/\./) >= 0) {
     if (urlLast == "index.html" || urlLast == "index.php") {
       urlSplit.splice(-1,1);
     } else {
       urlSplit[urlSplit.length-1] = urlLast.split(".").splice(0,1);
     }
   }
   s.prop14 = s.eVar27 = "rdo";
   s.prop15 = s.eVar28 = urlSplit[minorSectionIndex] || "";
   s.prop16 = s.eVar29 = urlSplit[minorSectionIndex+1] || "";
   pageNameString = urlSplit.splice(3).join(" | ");
   s.pageName = "rh | microsite | rdo | " + pageNameString;
   s.channel = "microsite";
   s.prop4 = s.eVar23 = encodeURI(document.URL);
   s.prop21 = s.eVar18 = coreUrl;
   s.prop2 = s.eVar22 = "en";
</script>
<script src='//www.redhat.com/j/rh_omni_footer.js' type='text/javascript'></script>
<script>
   if(navigator.appVersion.indexOf('MSIE')>=0)document.write(unescape('%3C')+'\!-'+'-')
</script>
<noscript>
<a href='http://www.omniture.com' title='Web Analytics'>
<img alt='' border='0' height='1' src='https://smtrcs.redhat.com/b/ss/redhatcom,redhatglobal/1/H.25.4--NS/0?[AQB]=3[AQE]' width='1'>
</a>
</noscript>
</div>
<!-- /DO NOT REMOVE/ -->
<!-- End SiteCatalyst code version: H.25.4 -->
<!-- End Omniture tracking -->

</body>
</html>
